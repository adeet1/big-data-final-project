{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "earlier-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import dask.dataframe as dd\n",
    "import dask.bag as db\n",
    "import tqdm \n",
    "\n",
    "from distributed import Client\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from IPython.display import display\n",
    "\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "general-contributor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Client</h3>\n",
       "<ul style=\"text-align: left; list-style: none; margin: 0; padding: 0;\">\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:45423</li>\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a></li>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3 style=\"text-align: left;\">Cluster</h3>\n",
       "<ul style=\"text-align: left; list-style:none; margin: 0; padding: 0;\">\n",
       "  <li><b>Workers: </b>2</li>\n",
       "  <li><b>Cores: </b>2</li>\n",
       "  <li><b>Memory: </b>4.29 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:45423' processes=2 threads=2, memory=4.29 GB>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set LOCAL to True for single-machine execution while developing\n",
    "# Set LOCAL to False for cluster execution\n",
    "LOCAL = True\n",
    "\n",
    "if LOCAL:\n",
    "    # This line creates a single-machine dask client\n",
    "    client = Client()\n",
    "else:    \n",
    "    # This line creates a SLURM cluster dask and dask client\n",
    "    # Logging outputs will be stored in /scratch/{your-netid}\n",
    "    \n",
    "    cluster = SLURMCluster(memory='256GB', cores=8, python='/scratch/work/public/dask/bin/python', \n",
    "                               local_directory='/tmp/{}/'.format(os.environ['SLURM_JOB_USER']),\n",
    "                               job_extra=['--output=/scratch/{}/slurm-%j.out'.format(os.environ['SLURM_JOB_USER'])])\n",
    "\n",
    "    cluster.submit_command = 'slurm'\n",
    "    cluster.scale(100)\n",
    "\n",
    "    display(cluster)\n",
    "    client = Client(cluster)\n",
    "\n",
    "display(client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "exotic-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/scratch/work/courses/DSGA1004-2021/movielens/ml-latest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "damaged-stations",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This dataset contains 100836 rows and 4 columns.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>429</td>\n",
       "      <td>595</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>429</td>\n",
       "      <td>588</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>429</td>\n",
       "      <td>590</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>429</td>\n",
       "      <td>592</td>\n",
       "      <td>5.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>429</td>\n",
       "      <td>432</td>\n",
       "      <td>3.0</td>\n",
       "      <td>828124615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating  timestamp\n",
       "0     429      595     5.0  828124615\n",
       "1     429      588     5.0  828124615\n",
       "2     429      590     5.0  828124615\n",
       "3     429      592     5.0  828124615\n",
       "4     429      432     3.0  828124615"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the ratings dataset\n",
    "ratings_df = pd.read_csv('ratings.csv').sort_values(by=\"timestamp\").reset_index(drop=True)\n",
    "print(\"This dataset contains {} rows and {} columns.\".format(len(ratings_df), ratings_df.shape[1]))\n",
    "ratings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-medline",
   "metadata": {},
   "source": [
    "Split each user's data into training-validation-test set. For each user, use 60% of their ratings for training, 20% for validation, and 20% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "growing-scoop",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each user, compute the number of ratings they submitted\n",
    "num_ratings_per_user = ratings_df.groupby('userId').count()['rating'] # only do the computation on the first 100 users for testing the code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "detailed-density",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204ea53742f3488a87b38b3268c0ce44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TO-DO: Will need to optimize this algorithm - it's quite slow\n",
    "# Create training, validation, and test sets for each user\n",
    "training_df = pd.DataFrame()\n",
    "val_df = pd.DataFrame()\n",
    "test_df = pd.DataFrame()\n",
    "for userId, num_ratings in tqdm.notebook.tqdm(list(zip(num_ratings_per_user.index, num_ratings_per_user))):\n",
    "    # Get all the ratings for this user\n",
    "    user_ratings = ratings_df[ratings_df['userId'] == userId].reset_index(drop=True)\n",
    "    \n",
    "    # Make the first 60% of this user's ratings the training set\n",
    "    index_train = int(0.6*num_ratings)\n",
    "    user_train = user_ratings.loc[:index_train-1, :]\n",
    "    \n",
    "    # Make the next 20% of this user's ratings the validation set\n",
    "    index_val = index_train + int(0.2*num_ratings)\n",
    "    user_val = user_ratings.loc[index_train:index_val-1, :]\n",
    "    \n",
    "    # Make the last 20% of this user's ratings the testing set\n",
    "    user_test = user_ratings.loc[index_val:, :]\n",
    "    \n",
    "    # Add this user's individual training, validation, and testing sets to the\n",
    "    # unified training, validation, and testing sets, respectively\n",
    "    training_df = pd.concat([training_df, user_train], axis=0)\n",
    "    val_df = pd.concat([val_df, user_val], axis=0)\n",
    "    test_df = pd.concat([test_df, user_test], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "radio-glossary",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "      ... \n",
       "301    100\n",
       "302    100\n",
       "303    100\n",
       "304    100\n",
       "305    100\n",
       "Name: userId, Length: 6255, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_df[\"userId\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "killing-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check (these two should match)\n",
    "print(num_ratings_per_user.sum()) # total number of ratings\n",
    "print(sum([len(training_df), len(val_df), len(test_df)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "genetic-press",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fewer-uruguay",
   "metadata": {},
   "source": [
    "Compute the mean rating of each movie by grouping by movieId, and aggregating by mean. Note that we don't want to explicitly compute the utility matrix, because doing so will take a very long time, and the resulting matrix will be very large and take up a lot of memory.\n",
    "\n",
    "We compute the 100 highest mean-rated movies from the training set. We will recommend these 100 movies to every single user in the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "behavioral-diagram",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of ratings for each movie\n",
    "num_ratings_per_movie = ratings_df.groupby(\"movieId\").count()[\"rating\"]\n",
    "\n",
    "# Remove any movies with less than 20 ratings\n",
    "ratings_df = ratings_df.join(num_ratings_per_movie, on = \"movieId\", rsuffix=\"_count\")\n",
    "ratings_df = ratings_df[ratings_df[\"rating_count\"] >= 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "worldwide-schedule",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([  1104,    318,    922,    898,    475,   1204,    246,    858,\n",
      "              1235, 168252,   2959,   1276,    750,    904,   1221,  48516,\n",
      "              1213,    930,   1267,    912,  58559,     50,   1197,    260,\n",
      "              1212,    926,   1245,    527,   3275,   1208,    933,   2329,\n",
      "              1196,   1233,   1252,   1198,   1193,   1089,    296,   2571,\n",
      "              2019,   1228,   1945,   1225,    908,   4973,   1199,   2160,\n",
      "              1242,    913,    356,   1172,   1136,    593,   7361,  57669,\n",
      "              4011,   5618,   3681,   1203,   3147,    741,   2324,   6016,\n",
      "              2028,   1201,   3037,  56782,   2067,   1210,  68157,   1262,\n",
      "              4226,   1250,   1272,   1207,   7153,  44555,    608,   1266,\n",
      "             78499,   5995,  92259,   4993,   1244,    111,    541,   1086,\n",
      "              1222,    720,   2502,  27773,   1223,   1258,   1704,   1673,\n",
      "             31658,    899,  38061,   1249],\n",
      "           dtype='int64', name='movieId')\n"
     ]
    }
   ],
   "source": [
    "mean_ratings = ratings_df[[\"movieId\", \"rating\"]].groupby(\"movieId\").mean()[\"rating\"]\n",
    "mean_ratings = mean_ratings.sort_values(ascending=False)\n",
    "R_i = mean_ratings.head(100).index\n",
    "print(R_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "informal-telephone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ab37ee5ec04f14aff26454b71a54d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/610 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rel = np.empty(shape=(len(val_df['userId'].unique()), 100))\n",
    "rel[:] = np.nan\n",
    "for user in tqdm.notebook.tqdm(list(val_df[\"userId\"].unique())):\n",
    "    # If the user rated less than 100 movies we dont need to sort, we can just take all of them\n",
    "    D_i = val_df[val_df['userId'] == user].sort_values(by='rating', ascending=False).head(100)['movieId']\n",
    "    for idx in range(len(R_i)):\n",
    "        movie = R_i[idx]      \n",
    "        if movie in D_i.values: \n",
    "            rel[int(user)-1, idx] = 1\n",
    "        else:\n",
    "            rel[int(user)-1, idx] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "banner-trouble",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
